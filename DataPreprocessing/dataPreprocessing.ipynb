{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-*-encoding:utf-8 -*-\n",
    "#!/usr/bin/python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "csv_data = '''A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "0.0,11.0,12.0,'''\n",
    "csv_data = unicode(csv_data)\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B\n",
       "0  1.0   2.0\n",
       "1  5.0   6.0\n",
       "2  0.0  11.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Eliminating samples or features with missing values\n",
    "df.dropna()\n",
    "df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,   2. ,   3. ,   4. ],\n",
       "       [  5. ,   6. ,   7.5,   8. ],\n",
       "       [  0. ,  11. ,  12. ,   6. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing missing data with mean interpolation\n",
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imr = imr.fit(df)\n",
    "imputed_data = imr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Handling categoical data\n",
    "'''\n",
    "df = pd.DataFrame([['green', 'M', 10.1, 'class1'],\n",
    "                   ['red', 'L', 13.5, 'class2'],\n",
    "                   ['blue', 'XL', 15.3, 'class1']])\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "\n",
    "#Mapping ordinal features\n",
    "size_mapping = {'XL':3, 'L':2, 'M':1}\n",
    "df['size'] = df['size'].map(size_mapping)\n",
    "\n",
    "#Encoding class labels\n",
    "class_mapping = {label : idx for idx,label in enumerate(np.unique(df['classlabel']))}\n",
    "df['classlabel'] = df['classlabel'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Partitioning a dataset in training and test sets\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash','Alcalinity of ash', 'Magnesium','Total phenols', 'Flavanoids',\n",
    "                   'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Features prepocessing includes two main methods\n",
    "One is normalization, another is standardization\n",
    "'''\n",
    "#N0rmalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)\n",
    "\n",
    "#Standardardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "X_train_std = std.fit_transform(X_train)\n",
    "X_test_std = std.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Selecting meaningful features\n",
    "In the overfitting case, there are 4 commmon ways\n",
    "1. More training data\n",
    "2. penalty\n",
    "3. simpler model\n",
    "4. reduce dimensionality for data\n",
    "'''\n",
    "#L1 regularization\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty = 'l1', C = 0.1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "Training_accuracy = lr.score(X_train_std, y_train)\n",
    "Testing_accuracy = lr.score(X_test_std, y_test)\n",
    "\n",
    "#Regularization path\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "colors = ['blue', 'green', 'red', 'cyan','magenta', 'yellow', 'black','pink', 'lightgreen', 'lightblue','gray', 'indigo', 'orange']\n",
    "weights, params = [], []\n",
    "for c in np.arange(-4,6):\n",
    "    lr = LogisticRegression(penalty='l1', C=10**c, random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**c)\n",
    "weights = np.array(weights)\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column],label=df_wine.columns[column+1], color=color)\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(1.38, 1.03), ncol=1, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "@Author: Darcy\n",
    "@Date: May, 17, 2017\n",
    "@Topic: SBS\n",
    "A classic sequential feature selection algorithm is Sequential Backward Selection (SBS)\n",
    "which aims to reduce the dimensionality of the initial feature subspace \n",
    "with a minimum decay in performance of the classifier \n",
    "to improve upon computational efficiency\n",
    "'''\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "'''\n",
    "@Author: Darcy\n",
    "@Date: May, 17, 2017\n",
    "@Topic: SBS\n",
    "A classic sequential feature selection algorithm is Sequential Backward Selection (SBS)\n",
    "which aims to reduce the dimensionality of the initial feature subspace \n",
    "with a minimum decay in performance of the classifier \n",
    "to improve upon computational efficiency\n",
    "'''\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SBS:\n",
    "\tdef __init__(self, estimator, k_features,scoring=accuracy_score,\n",
    "\t\t         test_size=0.25, random_state=1):\n",
    "\t\tself.scoring = scoring\n",
    "\t\tself.estimator = clone(estimator)\n",
    "\t\tself.k_features = k_features\n",
    "\t\tself.test_size = test_size\n",
    "\t\tself.random_state = random_state\n",
    "\n",
    "\tdef fit(self, X, Y):\n",
    "\t\tx_train, y_train, x_test, y_test = \\\n",
    "\t\t\t\ttrain_test_split(X, Y, test_size = self.test_size, \n",
    "\t\t\t\t\t\t\t\t\trandom_state = self.random_state) \n",
    "\t\tdim = np.shape(x_train)[1]\n",
    "\t\tself.indices = tuple(range(dim))\n",
    "\t\tself.subSets_ = [self.indices]\n",
    "\t\tscore = self.calScore(self.x_train, y_train, x_test, y_test, self.indices)\n",
    "\t\tself.scores_ = [score]\n",
    "\t\twhile dim > self.k_features:\n",
    "\t\t\tscores = []\n",
    "\t\t\tsubSet = []\n",
    "\t\t\tfor p in combinations(self.indices, dim - 1):\n",
    "\t\t\t\tscore = self.calScore(self.x_train, y_train, x_test, y_test, p)\n",
    "\t\t\t\tscores.append(score)\n",
    "\t\t\t\tsubSet.append(p)\n",
    "\t\t\tbest = np.argmax(score)\n",
    "\t\t\tself.indices = subSet[best]\n",
    "\t\t\tself.subSets_.append(self.indices)\n",
    "\t\t\tdim -= 1\n",
    "\t\t\tself.scores_.append(scores[best])\n",
    "\t\tself.k_score = self.scores_[-1]\n",
    "\t\treturn self\n",
    "\n",
    "\n",
    "\tdef calScore(self, x_train, y_train, x_test, y_test, indices):\n",
    "\t\tself.estimator.fit(x_train, y_train)\n",
    "\t\ty_pred = self.estimator.predict(x_test)\n",
    "\t\tscore = self.scoring(y_test, y_pred)\n",
    "\t\treturn score\n",
    "\n",
    "class SBS():\n",
    "\tdef __init__(self, estimator, k_features,\n",
    "            scoring=accuracy_score,\n",
    "            test_size=0.25, random_state=1):\n",
    "\t\tself.scoring = scoring\n",
    "\t\tself.estimator = clone(estimator)\n",
    "\t\tself.k_features = k_features\n",
    "\t\tself.test_size = test_size\n",
    "\t\tself.random_state = random_state\n",
    "        \n",
    "\tdef fit(self, X, y):\n",
    "\t\tX_train, X_test, y_train, y_test = \\\n",
    "\t\ttrain_test_split(X, y, test_size=self.test_size,\n",
    "\t\trandom_state=self.random_state)\n",
    "\t\tdim = X_train.shape[1]\n",
    "\t\tself.indices_ = tuple(range(dim))\n",
    "\t\tself.subsets_ = [self.indices_]\n",
    "\t\tscore = self._calc_score(X_train, y_train,\n",
    "\t\tX_test, y_test, self.indices_)\n",
    "\t\tself.scores_ = [score]\n",
    "\t\twhile dim > self.k_features:\n",
    "\t\t\tscores = []\n",
    "\t\t\tsubsets = []\n",
    "\t\t\tfor p in combinations(self.indices_, r=dim-1):\n",
    "\t\t\t\tscore = self._calc_score(X_train, y_train,\n",
    "\t\t\t\tX_test, y_test, p)\n",
    "\t\t\t\tscores.append(score)\n",
    "\t\t\t\tsubsets.append(p)\n",
    "\t\t\t\tbest = np.argmax(scores)\n",
    "\t\t\t\tself.indices_ = subsets[best]\n",
    "\t\t\t\tself.subsets_.append(self.indices_)\n",
    "\t\t\tdim -= 1\n",
    "\t\t\tself.scores_.append(scores[best])\n",
    "\t\tself.k_score_ = self.scores_[-1]\n",
    "\t\treturn self\n",
    "\n",
    "\tdef _calc_score(self, x_train, y_train, x_test, y_test, indices):\n",
    "\t\tself.estimator.fit(x_train, y_train)\n",
    "\t\ty_pred = self.estimator.predict(x_test)\n",
    "\t\tscore = self.scoring(y_test, y_pred)\n",
    "\t\treturn score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-c128ebdf9ae5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mk_fea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubsets_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fea\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Files\\anaconda\\lib\\site-packages\\matplotlib\\pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3152\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3153\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3155\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3156\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Files\\anaconda\\lib\\site-packages\\matplotlib\\__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1809\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1810\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1811\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1812\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Files\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'color'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1425\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Files\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Files\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Files\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must have same first dimension\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std, y_train)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "k_fea = [len(k) for k in sbs.subsets_]\n",
    "plt.plot(k_fea, sbs.scores_, marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
